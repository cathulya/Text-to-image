# Text-to-image
TEXT-TO-IMAGE SYNTHESIS USING GAN
Text-to-image synthesis involves computational techniques that transform human-written textual descriptions into visual representations. A significant challenge in creating realistic objects with semantic details is the disparity between the high-level concepts in text descriptions and the pixel-level content required for synthetic images. To address these limitations, this project uses a GAN-based T2I translator designed to bridge the cross-domain gap between visual and textual domains. This proposed model incorporates an attention module that focuses on the most relevant words within the textual descriptions.
